{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 0, Hypothesis : tensor([0., 0., 0., 0., 0.]) , Loss : 29661.801 \n",
      "Epoch : 1, Hypothesis : tensor([67.2550, 80.8370, 79.6496, 86.7367, 61.6576]) , Loss : 9299.042 \n",
      "Epoch : 2, Hypothesis : tensor([104.9094, 126.0961, 124.2437, 135.2988,  96.1786]) , Loss : 2916.040 \n",
      "Epoch : 3, Hypothesis : tensor([125.9912, 151.4358, 149.2109, 162.4876, 115.5064]) , Loss : 915.195 \n",
      "Epoch : 4, Hypothesis : tensor([137.7942, 165.6231, 163.1895, 177.7100, 126.3278]) , Loss : 288.001 \n",
      "Epoch : 5, Hypothesis : tensor([144.4023, 173.5664, 171.0157, 186.2326, 132.3867]) , Loss : 91.398 \n",
      "Epoch : 6, Hypothesis : tensor([148.1018, 178.0139, 175.3974, 191.0042, 135.7791]) , Loss : 29.769 \n",
      "Epoch : 7, Hypothesis : tensor([150.1729, 180.5040, 177.8505, 193.6756, 137.6786]) , Loss : 10.450 \n",
      "Epoch : 8, Hypothesis : tensor([151.3323, 181.8983, 179.2240, 195.1713, 138.7423]) , Loss : 4.394 \n",
      "Epoch : 9, Hypothesis : tensor([151.9812, 182.6791, 179.9928, 196.0086, 139.3380]) , Loss : 2.495 \n",
      "Epoch : 10, Hypothesis : tensor([152.3443, 183.1164, 180.4233, 196.4774, 139.6717]) , Loss : 1.899 \n",
      "Epoch : 11, Hypothesis : tensor([152.5474, 183.3614, 180.6642, 196.7398, 139.8587]) , Loss : 1.712 \n",
      "Epoch : 12, Hypothesis : tensor([152.6610, 183.4986, 180.7990, 196.8866, 139.9636]) , Loss : 1.652 \n",
      "Epoch : 13, Hypothesis : tensor([152.7243, 183.5757, 180.8744, 196.9688, 140.0226]) , Loss : 1.633 \n",
      "Epoch : 14, Hypothesis : tensor([152.7596, 183.6189, 180.9166, 197.0148, 140.0557]) , Loss : 1.627 \n",
      "Epoch : 15, Hypothesis : tensor([152.7792, 183.6432, 180.9402, 197.0404, 140.0745]) , Loss : 1.624 \n",
      "Epoch : 16, Hypothesis : tensor([152.7899, 183.6570, 180.9533, 197.0548, 140.0851]) , Loss : 1.623 \n",
      "Epoch : 17, Hypothesis : tensor([152.7958, 183.6648, 180.9606, 197.0627, 140.0913]) , Loss : 1.622 \n",
      "Epoch : 18, Hypothesis : tensor([152.7988, 183.6694, 180.9646, 197.0671, 140.0949]) , Loss : 1.621 \n",
      "Epoch : 19, Hypothesis : tensor([152.8004, 183.6720, 180.9668, 197.0695, 140.0972]) , Loss : 1.621 \n",
      "Epoch : 20, Hypothesis : tensor([152.8010, 183.6737, 180.9680, 197.0708, 140.0986]) , Loss : 1.620 \n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F \n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optimizer\n",
    "x_train = torch.Tensor(\n",
    "[\n",
    "    [73,80,75],\n",
    "    [93,88,93],\n",
    "    [89,91,90],\n",
    "    [96,98,100],\n",
    "    [73,66,70]\n",
    "    \n",
    "]\n",
    ")#5 x 3\n",
    "y_train = torch.Tensor(\n",
    "[\n",
    "    [152],[185],[180],[196],[142]\n",
    "]\n",
    ")# 5 x 1\n",
    "\n",
    "weight = torch.zeros((3,1) , requires_grad = True)\n",
    "bias = torch.zeros(1,requires_grad = True)\n",
    "optim = optimizer.SGD([weight,bias], lr = 1e-5)\n",
    "\n",
    "for Epoch in range(21):\n",
    "    hypothesis = x_train.matmul(weight) + bias\n",
    "    cost = torch.mean((hypothesis - y_train)**2)\n",
    "    optim.zero_grad()\n",
    "    cost.backward()\n",
    "    optim.step()\n",
    "    \n",
    "    print(\"Epoch : {0}, Hypothesis : {1:} , Loss : {2:.3f} \".format(Epoch,hypothesis.squeeze().detach(),cost.item()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 0, hypo : tensor([-54.6569, -65.5298, -64.6578, -70.5204, -49.8190]) cost : 54631.464844\n",
      "Epoch : 1, hypo : tensor([36.6225, 44.1819, 43.4427, 47.1984, 33.8637]) cost : 17124.994141\n",
      "Epoch : 2, hypo : tensor([ 87.7263, 105.6057, 103.9642, 113.1048,  80.7147]) cost : 5368.705078\n",
      "Epoch : 3, hypo : tensor([116.3373, 139.9947, 137.8479, 150.0033, 106.9450]) cost : 1683.733276\n",
      "Epoch : 4, hypo : tensor([132.3553, 159.2479, 156.8181, 170.6613, 121.6305]) cost : 528.689392\n",
      "Epoch : 5, hypo : tensor([141.3231, 170.0273, 167.4387, 182.2270, 129.8526]) cost : 166.644073\n",
      "Epoch : 6, hypo : tensor([146.3436, 176.0623, 173.3848, 188.7021, 134.4560]) cost : 53.161968\n",
      "Epoch : 7, hypo : tensor([149.1543, 179.4412, 176.7137, 192.3273, 137.0334]) cost : 17.590612\n",
      "Epoch : 8, hypo : tensor([150.7277, 181.3331, 178.5774, 194.3568, 138.4766]) cost : 6.440585\n",
      "Epoch : 9, hypo : tensor([151.6084, 182.3924, 179.6208, 195.4931, 139.2848]) cost : 2.945265\n",
      "Epoch : 10, hypo : tensor([152.1013, 182.9856, 180.2048, 196.1291, 139.7374]) cost : 1.849246\n",
      "Epoch : 11, hypo : tensor([152.3771, 183.3178, 180.5318, 196.4852, 139.9909]) cost : 1.505317\n",
      "Epoch : 12, hypo : tensor([152.5313, 183.5039, 180.7148, 196.6845, 140.1331]) cost : 1.397084\n",
      "Epoch : 13, hypo : tensor([152.6175, 183.6082, 180.8172, 196.7961, 140.2128]) cost : 1.362768\n",
      "Epoch : 14, hypo : tensor([152.6655, 183.6668, 180.8745, 196.8585, 140.2576]) cost : 1.351597\n",
      "Epoch : 15, hypo : tensor([152.6923, 183.6997, 180.9065, 196.8934, 140.2829]) cost : 1.347704\n",
      "Epoch : 16, hypo : tensor([152.7071, 183.7182, 180.9244, 196.9128, 140.2971]) cost : 1.346080\n",
      "Epoch : 17, hypo : tensor([152.7152, 183.7287, 180.9343, 196.9237, 140.3053]) cost : 1.345179\n",
      "Epoch : 18, hypo : tensor([152.7195, 183.7347, 180.9398, 196.9297, 140.3101]) cost : 1.344486\n",
      "Epoch : 19, hypo : tensor([152.7218, 183.7382, 180.9429, 196.9331, 140.3129]) cost : 1.343859\n",
      "Epoch : 20, hypo : tensor([152.7229, 183.7402, 180.9445, 196.9349, 140.3146]) cost : 1.343265\n"
     ]
    }
   ],
   "source": [
    "class MyLinearRegression(nn.Module):\n",
    "    def __init__(self,input_size,output_size):\n",
    "        super(MyLinearRegression,self).__init__()\n",
    "        self.Linear = nn.Linear(input_size,output_size)\n",
    "    def forward(self, x_train):\n",
    "        return self.Linear(x_train)\n",
    "    \n",
    "model = MyLinearRegression(3,1)\n",
    "\n",
    "optimizer_2 = optimizer.SGD(model.parameters(), lr = 1e-5)\n",
    "\n",
    "for Epoch in range(21):\n",
    "    hypothesis_2 = model(x_train)\n",
    "    cost = F.mse_loss(hypothesis_2,y_train)\n",
    "    optimizer_2.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer_2.step()\n",
    "    print(\"Epoch : {}, hypo : {} cost : {:.6f}\".format(Epoch,hypothesis_2.squeeze().detach(),cost.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
