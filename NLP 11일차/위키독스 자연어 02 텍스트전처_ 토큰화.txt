코퍼스 데이터에대한 전처리를 해야한다.

그 종류는 토큰화/정제/정규화 (tokenization/cleaning/normalization) 

* tokenization : corpus에서 토큰단어로 나누는작업 
nltk,konlpy에서 토큰화 작업을 해준다.

* 단어 기준으로 한다면 word tokenization 이고, 공통적으로 구두점(punctuation/ . ! ? ; )을
 없애는 작업도 포함한다.

* NLTK에서 word_tokenzie / sent_tokenize 의 함수를 지원한다.

* 토큰화 작업을  NLTK, OpenNLP, 스탠포드 CoreNLP, splitta, LingPipe  에서 수행한다.

// 토큰화 -> pos_tag 와 같은 어떤 단위생성을 포함한다.

1) morphs : 형태소 추출
2) pos : 품사 태깅(Part-of-speech tagging)
3) nouns : 명사 추출

--> 이러한 출력이 단위가 나오는 것을 토큰화라고 정의한다.

앞서 사용한 Okt 형태소 분석기와 결과가 다른 것을 볼 수 있습니다.
 각 형태소 분석기는 성능과 결과가 다르게 나오기 때문에, 
형태소 분석기의 선택은 사용하고자 하는 필요 용도에 어떤 형태소 분석기가 가장 적절한지를 판단하고 
사용하면 됩니다. 예를 들어서 속도를 중시한다면 메캅을 사용할 수 있습니다
